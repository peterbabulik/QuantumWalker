# A Computational Theory of Quantized Information and Emergent Reality:
Explorations with Quantum Walks, Cellular Automata, and Quantum Kernel Methods on Classical Simulators and Quantum Processing Units

## Abstract

This document outlines a theoretical framework proposing that reality is fundamentally composed of quantized information, processed by underlying quantum algorithms. We argue that the "geometrical shape" of observed physical phenomena is a direct manifestation of the "shape" or structure of these algorithms. To explore and demonstrate these propositions, we present results from a suite of computational experiments:
1.  Simulations of 1D and 2D Quantum Walks (QWs), including interactions with classical Cellular Automaton (CA) substrates (Rules 30, 90, and 110), and multi-walker systems, illustrating emergent complexity, particle-like behavior, and interactions.
2.  A conceptual "Entanglement Genesis Model" simulating the first few "Planck time folds" of an informationally minimal universe, demonstrating the algorithmic emergence of entanglement and state complexity.
3.  The development and simulation of a novel Quantum-Driven Cellular Automaton (QCA), where classical cell "types" evolve based on local quantum interactions, probed for computational complexity using Machine Learning (LSTM) models.
4.  Execution of selected quantum algorithms (QFT-based Matrix-Vector Multiplication and Quantum Kernel Methods for SVMs) on IBM Quantum Processing Units (QPUs), providing insights into NISQ-era hardware capabilities and limitations.

These diverse computational experiments serve to illustrate how complex dynamics can arise from simple, local, rule-based processing of quantum information, providing demonstrative support for the core tenets of the theory and highlighting paths for optimizing quantum algorithms for current hardware.

## 1. Core Theoretical Propositions

Our framework is built upon the following interconnected propositions:

**Proposition 1: Information is Quantized and Fundamental**
The basic constituents of reality are not continuous fields or infinitely divisible space, but discrete units of information. The most fundamental of these units can be represented by a qubit (or a small, fixed set of qubits). This implies:
*   **Discreteness:** Reality has a smallest scale at which information is encoded.
*   **Quantum Nature:** This information inherently possesses quantum properties like superposition and entanglement, allowing for a richer information processing capacity than classical bits.
*   **Minimal Information Unit:** The state of a fundamental "cell" or "entity" in this informational grid is described by a finite amount of quantum information (e.g., the state of a single qubit α|0⟩ + β|1⟩).

**Proposition 2: The "Geometrical Shape of Information" is Determined by the "Shape of the Quantum Algorithm"**
Physical reality, including the perception of space, time, particles, and their interactions, emerges from the execution of a fundamental quantum algorithm operating on this grid of quantized information.
*   **Algorithm as Law:** The specific rules (e.g., local unitary operations, interaction rules) that govern how information units update and influence each other constitute this algorithm.
*   **Information as State:** The "state of the universe" at any given "time" is the collective informational state of all its constituent units (e.g., a global state vector Ψ).
*   **Emergent Geometry:**
    *   The connectivity defined by the algorithm (which information units can influence which others) forms a computational graph, whose structure can be interpreted as an emergent (and potentially dynamic) "space."
    *   The patterns, distributions, and correlations that arise in the information state Ψ through the execution of the algorithm (e.g., probability distributions, entanglement structures, persistent patterns) define the "geometrical shapes" and properties of observed phenomena.
*   Thus, `Shape_of_Information(output) = Function(Shape_of_Algorithm(rules, connectivity, initial_state))`.

**Proposition 3: Particles, Fields, and Interactions are Emergent Phenomena**
Entities we perceive as particles, and the fields through which they interact, are not necessarily fundamental but are emergent properties or stable, propagating patterns within the evolving information state, generated by the underlying quantum algorithm.
*   A "particle" could be a localized, persistent excitation or pattern of information.
*   "Interactions" could be the result of these patterns influencing each other, possibly indirectly through modifications to a shared "substrate" or "field" (which itself is also an informational pattern).

**Proposition 4: The Quantum-to-Classical Transition as an Algorithmic Phase Change**
The transition from wave-like quantum behavior to particle-like classical behavior can be understood as a change in the effective quantum algorithm or a significant event within the algorithm's execution, as described by the conceptual equation:
`QW_wave_like(Rules_A, ψ_initial) --[t < t_measure]--> ψ_superposed_entangled`
`|| (Measurement/Transition Process at t_measure, Rules_A -> Rules_B) \/`
`QW_particle_like(Rules_B, ψ_collapsed_or_projected) --[t > t_measure]--> ψ_localized_disentangled`
This "measurement" or "transition" is not necessarily an external intervention but can be an emergent process where the system's own complex dynamics (e.g., interaction with a complex environment/substrate) lead to decoherence, state collapse, and a change in the dominant rules governing information propagation, resulting in classical-like localization and behavior.

## 2. Computational Explorations: Models and Simulations

To demonstrate and explore these propositions, we employ a variety of computational models, primarily executed using Qiskit Aer simulators.

### 2.1. Quantum Walks (QWs) on Classical Cellular Automaton (CA) Substrates

The QW framework provides a clear model for Propositions 1-3:
*   **Quantized Information:** The walker's internal coin state (qubit) and discrete lattice position.
*   **Quantum Algorithm:** The QW evolution `U_step = Shift_Operator @ Coin_Operator`.
*   **CA Substrate:** Classical CA patterns (Rule 30, 90, 110) serve as structured "environments" influencing the QW's coin operation locally, demonstrating how the substrate's "information geometry" (Prop. 2) shapes the walker's behavior.

**2.1.1. Single 1D Quantum Walker on CA Substrates**
*   **Setup:** A single QW with a 1-qubit coin. Coin operator depends on the CA cell state at the walker's position.
*   **Observations & Connection to Theory:**
    *   **`P(x,t)` (Probability Distribution):** The spatiotemporal patterns directly reflect the interaction between the QW rules and the CA substrate's geometry (Prop. 2). Different CA rules yield distinct `P(x,t)` shapes (e.g., structured spread on Rule 90, more diffuse on Rule 30).
    *   **`S_coin-pos(t)` (Entanglement):** Quantifies quantum correlations generated by the algorithm, varying with the CA substrate (Prop. 1 & 2).
    *   **Emergent Walker:** The walker's trajectory and properties are emergent from the algorithm (Prop. 3).
    *   **Aperiodic Substrates (Fibonacci, Thue-Morse):** QWs on these static, aperiodically ordered substrates (where CA cells are set to the sequence) were shown to generate complex, spiky, self-similar probability distributions and non-trivial entanglement dynamics, consistent with known results for QWs on quasi-crystals. Fractal dimension analysis (box-counting) of `P(x,t)` for the Thue-Morse QW yielded `Df ~ 0.7-0.8`, quantitatively demonstrating the emergence of fractal information shapes.

**2.1.2. Two Interacting 1D Quantum Walkers via a Dynamic CA Substrate**
*   **Setup:** Two QWs on the same lattice, coin operations depend on local CA state. The CA state evolves based on the combined probability distributions of *both* walkers (two-way coupling).
*   **Observations & Connection to Theory:**
    *   The CA becomes a dynamic "information field" mediating walker interactions (Prop. 3).
    *   The distance between walkers `|<x_A> - <x_B>|(t)` reveals emergent attraction or repulsion, a higher-order property of the coupled algorithm (Prop. 2 & 3).

**2.1.3. Simulating the Quantum-to-Classical Transition (Prop. 4)**
*   A dedicated simulation showed a QW transitioning from wave-like (Hadamard coin, spreading `P(x,t)`, growing `S(t)`) to particle-like behavior (Identity coin, localized `P(x,t)`, collapsed `S(t)`) after an imposed projective measurement. This directly models the "algorithmic phase change" concept.

### 2.2. Entanglement Genesis Model: "Planck Time Folding"

*   **Concept:** A toy model simulating the universe's proposed origin from a minimal quantum information state, evolving through iterative "algorithmic folds."
*   **Implementation:**
    1.  **t<sub>P1</sub> (Seed):** Starts with a single qubit (e.g., `|0⟩`).
    2.  **t<sub>P(n+1)</sub> (Fold n):** Each existing qubit from step `n` is entangled with a newly introduced ancilla qubit (e.g., via `H` on the existing qubit followed by `CX` to the new one). The number of qubits doubles at each step.
*   **Observations & Connection to Theory:**
    *   **Minimal Information to Complexity (Prop. 1):** Demonstrates how quantized information can proliferate.
    *   **Algorithmic Folding & Entanglement:** The simple, recursive folding rule generates Bell states (2 qubits), GHZ states (4 qubits), and increasingly complex multi-qubit entangled states with each step. This shows entanglement as an immediate consequence of information processing.
    *   **Growing Information Capacity:** The Hilbert space dimension `2^N` grows exponentially, as does the number of terms in the state's superposition.
    *   **"Shape of Algorithm" -> "Shape of Entangled State":** The specific folding rule dictates the precise structure (GHZ-like, etc.) of the emergent global entanglement.

### 2.3. Quantum-Driven Cellular Automata (QCA) & ML Analysis

*   **Concept:** A hybrid system where classical "cell types" on a 1D lattice evolve based on local quantum interactions.
    1.  **State:** Each of `N` "qunodes" has a classical type (A, B, or C).
    2.  **Quantum Step:** Based on current types, neighboring qunodes undergo specific 2-qubit unitary interactions (e.g., `U_AA`, `U_AB`). This step starts from a defined quantum state (e.g., all `|+⟩`, or `|0⟩/|1⟩` based on type).
    3.  **Outcome Extraction:** Marginal probabilities `P(q_i=1)` are calculated from the post-interaction global statevector.
    4.  **Classical Update:** Types `T_i(t+1)` are determined by a classical CA-like rule using `T_neighborhood(t)` and `P(q_neighborhood=1)(t)`.
*   **Exploration & Results:**
    *   Various QCA configurations (initial types/quantum states, interaction unitaries, type update rules) were simulated.
    *   **Emergent Dynamics:** Many rules led to simple (static or periodic) type evolutions. However, one 2-type configuration (`Exp2TypeComplex`: basis-state quantum init, all-CX interactions, sensitive thresholds) produced highly complex, chaotic-looking dynamics with glider-like structures over 200+ steps.
    *   **Machine Learning (LSTM) as Complexity Probe:** LSTMs were trained to predict the QCA type evolution.
        *   For simple/periodic QCAs, LSTMs achieved ~100% validation accuracy.
        *   For `Exp2TypeComplex`, LSTM accuracy dropped to ~53%, indicating its dynamics were hard to predict from local history and thus computationally richer.
    *   **Ouroboros Loop:** An automated loop was implemented to search for complex QCA rules by perturbing parameters if LSTM accuracy was high. It successfully identified a 3-type configuration that reduced LSTM accuracy from 100% to ~61%, demonstrating its utility in exploring the rule space.
*   **Connection to Theory:** This QCA model directly embodies Propositions 1-3, showing classical complex patterns emerging from local quantum-influenced rules. The LSTM analysis provides a quantitative measure of the "computational depth" or irreducibility of these emergent "shapes of information." The struggle of the LSTM with certain rules hints at the QCA potentially emulating computationally hard processes.

## 3. Experimental Validation on Quantum Processing Units (QPUs)

To bridge theory with practice and understand NISQ limitations, key algorithms were implemented on `ibm_brisbane` (127Q Eagle) using `qiskit-ibm-runtime` (v0.23.0) and `Qiskit-Terra` (v1.0.1).

### Case Study: QFT-based Matrix-Vector Multiplication on QPU
This case study investigated the feasibility of performing matrix-vector multiplication (`Y=AX`) using Quantum Fourier Transform (QFT) based arithmetic on the `ibm_brisbane` QPU. The experiments are primarily detailed in [`Matrix_VectorMultiplicationIBMbrisbane.ipynb`](https://github.com/peterbabulik/QuantumWalker/blob/main/Matrix_VectorMultiplicationIBMbrisbane.ipynb).

##### Objective & Approach (MatVec)
*   **Objective:** Compute each element `y_k = Σ_j A_kj * x_j`.
*   **Quantum Encoding:** Integer values of matrix/vector elements encoded into qubit states.
*   **Core Quantum Operations:** QFT-based quantum adders and multipliers.
*   **Circuit Structure:** Iterative computation and summation of terms `A_kj * x_j` into an accumulator register.

##### QPU Execution & Challenges (MatVec)
*   Utilized `qiskit-ibm-runtime.SamplerV2` (v0.23.0) and `Session`.
*   Transpiler `optimization_level=3` was used.
*   Learned that `SamplerV2` options for broad error mitigation (like `resilience_level`) are not set like `EstimatorV2`; specific suppression techniques (`dynamical_decoupling`, `twirling`) were enabled.

##### Results & Effectiveness (MatVec)
*   **Circuit Depth:** Extremely high even after transpilation (e.g., ~700-800+ gates for 3x3 MatVec).
*   **QPU Performance:** Heavily noise-dominated. For 3x3, a very faint signal for the correct answer was sometimes observed, but accuracy was low (<8%).
*   **MREM Attempt:** Custom MREM provided marginal improvements, indicating computational errors were dominant.
*   **Conclusion:** Direct QFT-based arithmetic for MatVec is currently impractical on NISQ devices due to excessive circuit depth.


#### Case Study: Quantum Kernel Methods for Classification on IBM QPUs
This case study pivoted to Quantum Kernel Methods, a Quantum Machine Learning technique, evaluating its performance on IBM QPUs. The main experiments are found in a notebook like `QuantumKernelSVM_QPU_Aer.ipynb`.

##### Objective & Approach (Kernels)
*   **Objective:** Compute kernel matrices `K_ij = f(|⟨φ(X_i)|φ(X_j)⟩|^2)` on `AerSimulator` and `ibm_brisbane`, and use them with classical SVMs.
*   **Feature Map `φ(x)`:** Primarily a simple `Ry(x_k)` encoding per feature on data qubits. A "neural-inspired" map (classical `tanh` preprocessing + Ry encoding + CNOTs) was also tested.
*   **Kernel Entry Estimation:** "Compute-uncompute" method for fidelity (`P(|0...0⟩)` after `Uφ(Xj)† Uφ(Xi) |0⟩`), executed via batched `SamplerV2` jobs.
*   **Kernel Transformations:** 'linear', 'RBF-like', 'polynomial' from fidelities.
*   **QPU Settings:** `ibm_brisbane`, `qiskit-ibm-runtime` v0.23.0, `Qiskit (Terra)` v1.0.1, `SamplerV2` with `dynamical_decoupling` & `twirling`, 4096 shots, transpiler `optimization_level=0` for fidelity circuits.

##### Datasets Used (Kernels)
*   `sklearn.datasets.make_moons`
*   `sklearn.datasets.load_breast_cancer` (subset, 4 features)
*   Custom "Quantum Interference Dataset" (2 features, designed to be challenging)

##### Key Results & Findings (Kernels)
*   **Successful QPU Pipeline:** Batch submission to `SamplerV2` was effective.
*   **Simple Ry Feature Map Performance:**
    *   **Shallow Circuits:** Fidelity circuits were very shallow (ISA depth ~11 for 2 qubits).
    *   **High Fidelity on QPU:** QPU kernel entries were remarkably close to Aer for `make_moons` and Breast Cancer subset.
    *   **Excellent SVM Accuracy (Easier Data):** QPU-kernel SVMs achieved high accuracy (often 100% on small test subsets), matching Aer and classical SVMs.
    *   **"Quantum Interference Dataset":**
        *   Classical RBF struggled (~50-62% accuracy).
        *   Ideal Aer quantum kernels outperformed classical RBF (~60-67%).
        *   QPU quantum kernels (on a subset) performed worse than Aer (e.g., 33% vs 60-67%), showing sensitivity to noise for this harder dataset despite shallow circuits. Increased shots (4096) did not fully overcome this for the harder dataset instance.
*   **Neural-Inspired Feature Map (Breast Cancer Subset):**
    *   Aer performance (70%) was worse than simple Ry map and classical RBF.
    *   QPU performance further degraded (60%), showing that unoptimized complexity + noise is detrimental.
*   **Computational Cost:** Aer simulation of kernels is time-consuming. QPU wall-clock time is also significant due to overhead, though actual QPU quantum time per job (from IBM dashboard) is short for shallow circuits.

##### Conclusions for Quantum Kernel Case Study
*   Computing quantum kernels on current QPUs is feasible and can yield good quality entries for **shallow feature maps**.
*   The choice of feature map is paramount. Simple maps can be effective and noise-robust.
*   For harder classification tasks, SVM performance becomes more sensitive to noise in QPU-computed kernel entries.
*   A robust QPU execution pipeline (batching, appropriate Sampler options, transpiler optimization) is essential.

---

## 4. Overall Conclusions & Future Directions (incorporating all experiments)

This project, through a synergistic combination of theoretical development, diverse classical simulations (QWs, QW-CA, QCA), and real QPU experiments (MatVec, Quantum Kernels), provides compelling illustrations for a computational, information-based view of reality.

**Key Synthesized Learnings:**

1.  **Algorithmic Origin of Complexity:** Simple, local algorithmic rules (whether in QWs, CAs, or the quantum-driven QCAs) demonstrably lead to rich emergent global patterns, including fractal geometries and computationally complex dynamics. This strongly supports the core tenet that the "shape of information" is a direct output of the "shape of the algorithm."
2.  **Circuit Depth as a NISQ Constraint:** QPU experiments starkly contrasted the failure of deep QFT-based arithmetic circuits with the success of shallow quantum kernel fidelity estimation circuits. Minimizing circuit depth is paramount for obtaining meaningful results on current quantum hardware.
3.  **Quantum Kernels on NISQ:** Shallow quantum feature maps can produce kernel matrices on QPUs with sufficient quality for effective use in ML tasks like SVMs, sometimes matching ideal simulation performance on simpler datasets. However, for more complex datasets or feature maps, QPU noise degrades kernel quality and subsequent ML accuracy.
4.  **Quantum-Driven CAs as Models of Emergence:** The developed QCA model, where classical information (types) evolves based on underlying quantum interactions, serves as a powerful tool for studying emergent computation. The use of LSTMs as a "complexity meter" for these QCAs is a novel approach to identify rule sets capable of generating hard-to-predict, potentially TC-like dynamics.
5.  **Practical QPU Execution:** Effective use of `qiskit-ibm-runtime` involves careful management of `SamplerV2` options (specific suppression techniques like DD/Twirling, as general resilience levels aren't directly applicable to Sampler like they are to Estimator), efficient batching of circuits within `Session` contexts, and robust transpilation strategies.

**Future Directions:**

*   **Deep Dive into Complex QCAs:** Further analyze the `Exp2TypeComplex` QCA (and any new ones found by the Ouroboros loop) for specific computational primitives (gliders, logic gates).
*   **Refine Ouroboros Loop:** Implement more sophisticated search and fitness evaluation strategies (e.g., incorporating multiple complexity metrics beyond LSTM predictability) to discover computationally richer QCA rules.
*   **Advanced Quantum Feature Maps:** Design and test more expressive (but still NISQ-tractable) parameterized quantum circuits as feature maps for the kernel method. Explore variational quantum kernels where feature map parameters are optimized.
*   **Measurement Error Mitigation (MREM):** Resolve Qiskit 1.0 MREM tool import issues (likely environment-specific) and apply robust MREM to QPU-derived kernel entries and QCA quantum outcomes to improve result fidelity.
*   **Scaled QPU Experiments:** As hardware access and capabilities allow, run promising kernel and QCA experiments on larger numbers of qubits and for more samples/longer depths.
*   **Theoretical Refinement:** Continue to develop the mathematical and conceptual links between the toy model simulations (Entanglement Genesis, QW-CA, QCA) and the broader theoretical propositions regarding fundamental physics (spacetime, particles, forces, cosmology).

This project underscores the power of computational experimentation in exploring foundational questions and the exciting, albeit challenging, landscape of NISQ-era quantum computing. The interplay between simple quantum rules and emergent classical complexity offers a rich field for future investigation.

